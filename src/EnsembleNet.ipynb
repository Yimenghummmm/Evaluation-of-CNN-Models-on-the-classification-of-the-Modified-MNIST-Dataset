{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introduction\nhttps://www.kaggle.com/tonysun94/pytorch-1-0-1-on-mnist-acc-99-8/notebook\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_images = pd.read_pickle('/kaggle/input/modified-mnist/train_max_x')\ntrain_df_y = pd.read_csv('/kaggle/input/modified-mnist/train_max_y.csv')\ntest_images = pd.read_pickle('/kaggle/input/modified-mnist/test_max_x')\n\n# have a glimpse of data structrure\nn_train = len(train_images)\nn_pixels = len(train_images[0])\nprint('Number of training samples: {0}'.format(n_train))\nprint('Number of training pixels: {0}'.format(n_pixels))\n\nn_test = len(test_images)\nn_pixels = len(test_images[0])\nprint('Number of test samples: {0}'.format(n_test))\nprint('Number of test pixels: {0}'.format(n_pixels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Displaying Some Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_sel = np.random.randint(n_train, size=8)\n\ngrid = make_grid(torch.Tensor((train_images[random_sel]/255.).reshape((-1,128,128))).unsqueeze(1), nrow=8)\nplt.rcParams['figure.figsize'] = (16,2)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.axis('off')\nprint(*list(train_df_y.iloc[random_sel, 0].values), sep=', ')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Noise Reduction\nRefer to 'Data Cleaning' notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"def filter_image(img):\n    image = np.array(img, dtype=np.uint8)\n    image = (255-image)\n    kernel = np.ones((1,1),np.uint8)\n\n    median = cv2.medianBlur(image, 1)\n\n    thresh = cv2.threshold(median.copy(), 60, 255, cv2.THRESH_BINARY)[1]\n    \n    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n\n    return opening","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x_train_imgs = np.full(train_images.shape, 0)\n# x_test_imgs = np.full(test_images.shape, 0)\nx_train_imgs = train_images\nx_test_imgs = test_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range (0, len(train_images)):\n#     x_train_imgs[i] = filter_image(train_images[i])\n    \n# for i in range (0, len(test_images)):\n#     x_test_imgs[i] = filter_image(test_images[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean the Data\nWe will remove some noise using a blurring method and then thresholding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(x_train_imgs, train_df_y.Label.values.astype(int), test_size=0.1) #random state 42 can be added\nprint(X_train.shape, X_val.shape)\nprint(y_train.shape,y_val.shape )\nprint(y_train[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Construct Data Sets\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n\nclass ModifiedMNIST(torch.utils.data.Dataset):\n    \"\"\"\n    This is our custom dataset class which will load images, perform transforms on them, and load their corresponding labels\n    \"\"\"\n    \n    def __init__(self, imgs=None, labels=None, transform=None):\n        self.X = imgs\n        self.y = labels\n            \n#         self.transform = Compose([Resize((224, 224)), ToTensor(), Normalize((self.X.mean()/255,), (self.X.std()/255,))])\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        if self.y is not None:\n            return self.transform(self.X[idx]), self.y[idx]\n        else:\n            return self.transform(self.X[idx])\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nRandAffine = transforms.RandomAffine(degrees=20, translate=(0.05, 0.05), scale=(0.9, 1.1))\n\ntrain_transforms = transforms.Compose(\n    [transforms.ToPILImage(),\n#      transforms.Grayscale(num_output_channels=1),\n     Resize((224, 224)),\n     RandAffine,\n     transforms.ToTensor(),\n     transforms.Normalize((x_train_imgs.mean()/255,), (x_train_imgs.std()/255,))])\n\nval_test_transforms = transforms.Compose(\n    [transforms.ToPILImage(),\n#      transforms.Grayscale(num_output_channels=1),\n     Resize((224, 224)),\n     transforms.ToTensor(),\n     transforms.Normalize((x_train_imgs.mean()/255,), (x_train_imgs.std()/255,))])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Modified ResNet\nWe will follow this tutorial found online\nhttps://zablo.net/blog/post/using-resnet-for-mnist-in-pytorch-tutorial/index.html\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.models.resnet import ResNet, BasicBlock\n\nclass MnistResNet(ResNet):\n    def __init__(self):\n        super(MnistResNet, self).__init__(BasicBlock, [2,2,2,2], num_classes=10)\n        self.conv1 = torch.nn.Conv2d(1, 64,\n                                    kernel_size = (7,7),\n                                    stride=(2,2),\n                                    padding=(3,3), bias = False)\n\n    \n# model = MnistResNet()\n# print(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating an Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append(MnistResNet())\nmodels.append(MnistResNet())\nmodels.append(MnistResNet())\nmodels.append(MnistResNet())\n# models.append(MnistResNet())\n# models.append(MnistResNet())\n# models.append(MnistResNet())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.autograd import Variable\ndef train(train_loader, model, criterion, optimizer, epoch):\n    model.train()\n    \n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = Variable(data), Variable(target)\n        \n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        \n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        \n        loss.backward()\n        optimizer.step()\n        \n        if (batch_idx + 1)%100 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n                100. * (batch_idx + 1) / len(train_loader), loss.data.item()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate(val_loader, model, criterion):\n    model.eval()\n    loss = 0\n    correct = 0\n    \n    for _, (data, target) in enumerate(val_loader):\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        \n        output = model(data)\n        \n        loss += criterion(output, target).data.item()\n\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n        \n    loss /= len(val_loader.dataset)\n        \n    print('\\nOn Val set Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n        loss, correct, len(val_loader.dataset),\n        100.0 * float(correct) / len(val_loader.dataset)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# example config, use the comments to get higher accuracy\ntotal_epoches = 20 # 50\nstep_size = 5     # 10\nbase_lr = 0.01    # 0.01\n\n# optimizer = optim.Adam(model.parameters(), lr=base_lr)\n# criterion = nn.CrossEntropyLoss()\n# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n\n# if torch.cuda.is_available():\n#     model = model.cuda()\n#     criterion = criterion.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(models)):\n    train_dataset = ModifiedMNIST(X_train, y_train, transform=train_transforms)\n    val_dataset = ModifiedMNIST(X_val, y_val, transform=val_test_transforms)\n\n    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                            batch_size=batch_size, shuffle=True)\n    val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n                                            batch_size=batch_size, shuffle=False)\n    \n    model = models[i]\n    optimizer = optim.Adam(model.parameters(), lr=base_lr)\n    criterion = nn.CrossEntropyLoss()\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n\n    if torch.cuda.is_available():\n        model = model.cuda()\n        criterion = criterion.cuda()\n    for epoch in range(total_epoches):\n        print(\"\\nTrain Epoch {}: lr = {}\".format(epoch, exp_lr_scheduler.get_lr()[0]))\n\n        train(train_loader=train_loader, model=model, criterion=criterion, optimizer=optimizer, epoch=epoch)\n        validate(val_loader=val_loader, model=model, criterion=criterion)\n        exp_lr_scheduler.step()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for epoch in range(total_epoches):\n#     print(\"\\nTrain Epoch {}: lr = {}\".format(epoch, exp_lr_scheduler.get_lr()[0]))\n    \n#     train_dataset = ModifiedMNIST(X_train, y_train, transform=train_transforms)\n#     val_dataset = ModifiedMNIST(X_val, y_val, transform=val_test_transforms)\n\n#     train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n#                                                batch_size=batch_size, shuffle=True)\n#     val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n#                                              batch_size=batch_size, shuffle=False)\n\n#     train(train_loader=train_loader, model=model, criterion=criterion, optimizer=optimizer, epoch=epoch)\n#     validate(val_loader=val_loader, model=model, criterion=criterion)\n#     exp_lr_scheduler.step()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction(test_loader, model):\n    model.eval()\n    test_pred = torch.LongTensor()\n    \n    for i, data in enumerate(test_loader):\n        if torch.cuda.is_available():\n            data = data.cuda()\n            \n        output = model(data)\n        \n        pred = output.cpu().data.max(1, keepdim=True)[1]\n        test_pred = torch.cat((test_pred, pred), dim=0)\n        \n    return test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n\ntest_batch_size = 64\ntest_dataset = ModifiedMNIST(imgs=test_images, transform=val_test_transforms)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=test_batch_size, shuffle=False)\n\n# tensor prediction\nlabels = []\nfor model in models:\n    model_pred = prediction(test_loader, model)\n    labels.append(model_pred.numpy())\n\n    \nlabels = np.array(labels)\n# labels = np.transpose(labels, (1,0))\nlabels = stats.mode(labels)[0]\n# lables = np.squeeze(labels)\nlabels = labels[0]\nprint(labels.shape)\n\nlabels = np.transpose(labels, (1,0))\nlabels = np.squeeze(labels)\n\ntest_pred_df = pd.DataFrame({'Id' : np.arange(0, model_pred.shape[0]), 'Label' : labels})\n\n# test_pred = prediction(test_loader, model)\n\n# # tensor -> numpy.ndarray -> pandas.DataFrame\n# test_pred_df = pd.DataFrame(np.c_[np.arange(0, len(test_dataset)), test_pred.numpy()], \n#                       columns=['Id', 'Label'])\n\n# # show part of prediction dataframe\nprint(test_pred_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = make_grid(torch.Tensor((x_train_imgs[random_sel]/255.).reshape((-1,128,128))).unsqueeze(1), nrow=8)\nplt.rcParams['figure.figsize'] = (16,2)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.axis('off')\nprint(*list(train_df_y.iloc[[0,1,2,3,4,5,6,7], 0].values), sep=', ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(test_pred_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# file.remove(\"/kaggle/working/submission_RESNET18.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_df.to_csv('submission_ensemble.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Saving Model for Future Use"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models[0]\ncheckpoint = {'model': MnistResNet(),\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint1.pth')\n\nmodel = models[1]\ncheckpoint = {'model': MnistResNet(),\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint2.pth')\n\nmodel = models[2]\ncheckpoint = {'model': MnistResNet(),\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint3.pth')\n\nmodel = models[3]\ncheckpoint = {'model': MnistResNet(),\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint4.pth')\n\n# model = models[4]\n# checkpoint = {'model': MnistResNet(),\n#               'state_dict': model.state_dict(),\n#               'optimizer' : optimizer.state_dict()}\n\n# torch.save(checkpoint, 'checkpoint5.pth')\n\n# model = models[5]\n# checkpoint = {'model': MnistResNet(),\n#               'state_dict': model.state_dict(),\n#               'optimizer' : optimizer.state_dict()}\n\n# torch.save(checkpoint, 'checkpoint6.pth')\n\n# model = models[6]\n# checkpoint = {'model': MnistResNet(),\n#               'state_dict': model.state_dict(),\n#               'optimizer' : optimizer.state_dict()}\n\n# torch.save(checkpoint, 'checkpoint7.pth')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_checkpoint(filepath):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint['state_dict'])\n    for parameter in model.parameters():\n        parameter.requires_grad = False\n    \n    model.eval()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_checkpoint('checkpoint1.pth')\nprint(model)\nmodel = load_checkpoint('checkpoint2.pth')\nprint(model)\nmodel = load_checkpoint('checkpoint3.pth')\nprint(model)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}