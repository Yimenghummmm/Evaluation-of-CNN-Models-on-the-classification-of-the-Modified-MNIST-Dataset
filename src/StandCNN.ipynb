{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Import"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nimport logging\nimport random\nimport warnings\nfrom datetime import datetime\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom torch import nn\nfrom torchvision import models, transforms\nfrom torchvision.models import resnet, densenet, squeezenet\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\nimport torch.nn.functional as F\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport math\n# for creating validation set\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nimport pdb\ntorch.set_printoptions(linewidth=120)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.Data Load && Preprocess"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_images = pd.read_pickle('/kaggle/input/modified-mnist/train_max_x') \ntest_images = pd.read_pickle('/kaggle/input/modified-mnist/test_max_x')\ntrain_label = pd.read_csv('/kaggle/input/modified-mnist/train_max_y.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_images.shape)\nprint(train_label.shape)\nprint(test_images.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_size = plt.rcParams[\"figure.figsize\"] \nplot_size[0] = 8\nplot_size[1] = 6\nplt.rcParams[\"figure.figsize\"] = plot_size \ntrain_label.Label.value_counts().plot(kind='pie',autopct='%1.0f')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (8, 5)\nplt.bar(train_label['Label'].value_counts().index, train_label['Label'].value_counts())\nplt.xticks(np.arange(10))\nplt.xlabel('Class', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.grid('on', axis='y')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Gaussian Filter"},{"metadata":{"trusted":true},"cell_type":"code","source":"def filter_image(img):\n    image = np.array(img, dtype=np.uint8)\n    image = (255-image)\n    kernel = np.ones((1,1),np.uint8)\n\n    median = cv2.medianBlur(image, 1)\n\n    thresh = cv2.threshold(median.copy(), 60, 255, cv2.THRESH_BINARY)[1]\n    \n    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n\n    return opening","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.utils import make_grid\n\nrandom_sel = np.random.randint(len(train_images), size=8)\n\ngrid = make_grid(torch.Tensor((train_images[random_sel]/255).reshape((-1,128,128))).unsqueeze(1), nrow=8)\nplt.rcParams['figure.figsize'] = (16,2)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.suptitle('Random samples before filtering')\nplt.axis('off')\nprint(*list(train_label.iloc[random_sel, 0].values), sep=', ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfor i in range(0, len(train_images)):\n    train_images[i] = filter_image(train_images[i])\nfor i in range(0, len(test_images)):\n    test_images[i] = filter_image(test_images[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = make_grid(torch.Tensor((train_images[random_sel]/255).reshape((-1,128,128))).unsqueeze(1), nrow=8)\nplt.rcParams['figure.figsize'] = (16,2)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.suptitle('Random samples after filtering')\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train_images/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = make_grid(torch.Tensor((train_images[random_sel]).reshape((-1,128,128))).unsqueeze(1), nrow=8)\nplt.rcParams['figure.figsize'] = (16,2)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.suptitle('Random samples after Normalization')\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Split && loader packing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# preprocessing and formatting\nx_train = np.floor(train_images).reshape(-1, 128, 128)\ny_train = train_label.Label.values.reshape(-1)\nx_test  = np.floor(test_images).reshape(-1, 128, 128)\n\n# training-validation split\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2)   \n\nx_train = torch.from_numpy(x_train).float().unsqueeze(1)\ny_train = torch.from_numpy(y_train).long()\n\nx_valid = torch.from_numpy(x_valid).float().unsqueeze(1)\ny_valid = torch.from_numpy(y_valid).long()\n\nx_test  = torch.from_numpy(x_test).float().unsqueeze(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape, y_train.shape, x_valid.shape, y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.utils.data as Data\n# create torch dataset and dataloader\ntrain_dataset = Data.TensorDataset(x_train, y_train)\ntrain_loader  = Data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n\nvalid_dataset = Data.TensorDataset(x_valid, y_valid)\nvalid_loader  = Data.DataLoader(valid_dataset, batch_size=64, shuffle=True)\n\ntest_loader   = Data.DataLoader(x_test, batch_size=64, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (x_train.shape, y_train.shape), (val_x.shape, val_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_x = x_train.reshape(40000,1,128,128)\n# train_x = torch.from_numpy(train_x)\n# train_y = y_train.astype(int)\n# train_y = torch.from_numpy(train_y)\n# train_x.shape, train_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_x = val_x.reshape(10000,1,128,128)\n# val_x = torch.from_numpy(val_x)\n# val_y = val_y.astype(int)\n# val_y = torch.from_numpy(val_y)\n# val_x.shape, val_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torch.utils.data as utils\n# train_data = utils.TensorDataset(train_x,train_y) # create your datset\n# test_data = utils.TensorDataset(val_x,val_y) # create your datset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_loader = utils.DataLoader(train_data,batch_size = 64) # create your dataloader\n# test_loader = utils.DataLoader(test_data,batch_size = 64) # create your dataloader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Models"},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Model 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net1(nn.Module): \n    def __init__(self):\n        super(Net1, self).__init__()\n          \n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True), \n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n        )\n          \n        self.classifier = nn.Sequential(\n            nn.Dropout(p = 0.5),\n            nn.Linear(4096, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p = 0.5),\n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p = 0.5),\n            nn.Linear(512, 10),\n        )\n          \n        for m in self.features.children():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        \n        for m in self.classifier.children():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform(m.weight)\n            elif isinstance(m, nn.BatchNorm1d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n                \n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        \n        return x     ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 random test to validate if the model was well defined"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_conv_net = Net1()\ntest_x = torch.rand(2, 1, 128, 128)\ntest_y = test_conv_net(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(epoch):\n    model.train()\n    exp_lr_scheduler.step()\n    train_loss = 0\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = Variable(data), Variable(target)\n        \n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        \n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        train_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n        if (batch_idx + 1)% 100 == 0:\n            print('Train Epoch: {}| lr: {}, |Batch: [{}/{} ({:.0f}%)] \\t | Loss: {:.6f}'.format(\n                epoch,\n                exp_lr_scheduler.get_lr()[0],\n                (batch_idx + 1) * len(data),\n                len(train_loader.dataset),\n                100. * (batch_idx + 1) / len(train_loader),\n                loss.data))\n    tr_loss.append(train_loss / (batch_idx+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(data_loader):\n    model.eval()\n    loss = 0\n    correct = 0\n    for data, target in data_loader:\n        data, target = Variable(data, volatile=True), Variable(target)\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        \n        output = model(data)\n        \n        loss += F.cross_entropy(output, target, size_average=False).data\n\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n        \n    loss /= len(data_loader.dataset)\n        \n    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n        loss, \n        correct, \n        len(data_loader.dataset),\n        100. * correct / len(data_loader.dataset)))\n    val_loss.append(loss.item())\n    val_acc.append((100. * correct / len(data_loader.dataset)).item())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Training"},{"metadata":{},"cell_type":"markdown","source":"## 5.1 StandCNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Net1()\n\noptimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n\ncriterion = nn.CrossEntropyLoss()\n\nexp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7,gamma=0.1)\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 50\nepoch_nums = []\ntr_loss = []\nval_loss = []\nval_acc = []\nfor epoch in range(n_epochs):\n    train(epoch)\n    evaluate(valid_loader)\n    epoch_nums.append(epoch)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## save the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = {'model': Net1(),\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'CNN13.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'CNN13.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(epoch_nums),len(tr_loss),len(val_loss), len(val_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_res = pd.DataFrame({\n                'Epochs': epoch_nums,\n                'train loss':tr_loss,\n                'validation loss': val_loss,\n                'validation Accuracy': val_acc\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_res.to_csv('CNN13.csv',index=False)\nFileLink(r'CNN13.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}